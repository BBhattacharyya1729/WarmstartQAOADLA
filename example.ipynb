{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c1f4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QAOAUtils import * \n",
    "from LieUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a40b45",
   "metadata": {},
   "source": [
    "This notebook is meant as a review of QAOA/Warmstart utils plus an intro to the DLA functionality. We start by generating a 5-vertex (equivalently 5 qubit) adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186f569a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 1, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 8\n",
    "A= rand_adj(n)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1577ee",
   "metadata": {},
   "source": [
    "### Review of Warmstart Calculations\n",
    "\n",
    "Because we already have seen that BM performs worse than GW almost universally, we will mainly be concerned with GW for now. We can consider other warmstarts later.\n",
    "\n",
    "We always rotate on the first qubit for vertex on top rotations (arbitrary choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1fb3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = GW(A)  ###calculate the full GW embedding\n",
    "_,GW2_angles,_ = GW2(A,GW_Y=Y) ###project to 2d angles using precalculated GW embedding \n",
    "_,GW3_angles,_ = GW3(A,GW_Y=Y) ###project to 2d angles using precalculated GW embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9737cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Get circuit information for each warmstart. Circuit information consists of the initial state + the mixer operators for each qubit\n",
    "GW2_circ_data = Q2_data(GW2_angles,rotation = 0)\n",
    "GW3_circ_data = Q3_data(GW3_angles,rotation = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce3750",
   "metadata": {},
   "source": [
    "Now we can use these results to evaluate some randomized QAOA circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f1e68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "precomp  = pre_compute(A) ###compute the Hamiltonian information for the cost layers (shared for all circuits)\n",
    "HC = np.diag(precomp) ###compute explicit hamiltonian for later\n",
    "p = 40 ###depth of the circuits\n",
    "circuit_params  = np.random.random(2*p) * 2 * np.pi ###circuit parameters\n",
    "\n",
    "###split circuit params into gammas and betas\n",
    "gammas = circuit_params[p:]\n",
    "betas = circuit_params[:p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac9158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_QAOA  = QAOA_eval(precomp,circuit_params,mixer_ops=None,init=None)\n",
    "GW2_QAOA  = QAOA_eval(precomp,circuit_params,mixer_ops=GW2_circ_data[1],init=GW2_circ_data[0])\n",
    "GW3_QAOA  = QAOA_eval(precomp,circuit_params,mixer_ops=GW3_circ_data[1],init=GW3_circ_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17c3a2b",
   "metadata": {},
   "source": [
    "### Comparison to exact matrix computation.\n",
    "\n",
    "Remember that the QAOA circuit is of the form \n",
    "$$|\\psi\\rangle = \\prod_{m=1}^p e^{-\\beta_m H_B } e^{-\\gamma_m H_C }|\\psi_\\textrm{init}\\rangle$$\n",
    "\n",
    "When choosing warmstarts, we can choose both $|\\psi_\\textrm{init}\\rangle$ (the initial state) and $H_B$ (the mixer Hamiltonian). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5316863a",
   "metadata": {},
   "source": [
    "For the two dimensional warmstart we have \n",
    "$$|\\psi_\\textrm{int}\\rangle   = \\bigotimes_{j=0}^{n-1} \\left[\\cos\\left(\\frac{\\theta_j}{2}\\right)|0\\rangle + e^{-i\\pi/2}\\sin\\left(\\frac{\\theta_j}{2}\\right)|1\\rangle\\right]$$\n",
    "$$H_B = \\bigoplus_{j=0}^{n-1} (-\\sin(\\theta_j) Y + \\cos(\\theta_j)Z)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4616a9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.329070518200751e-15-9.860761315262648e-32j)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GW2_rotated_angles = vertex_on_top(GW2_angles,0)\n",
    "\n",
    "GW2_HB = Q2_Hamiltonian(GW2_rotated_angles)\n",
    "GW2_psi_init = GW2_circ_data[0]\n",
    "\n",
    "np.linalg.eigvalsh(GW2_HB)[-1] - GW2_psi_init.conjugate().T @ GW2_HB @ GW2_psi_init  ###The initial state is always the maximal eigenvalue of the HB operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd95f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000462"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GW2_psi = GW2_psi_init\n",
    "\n",
    "for i in range(p):\n",
    "    GW2_psi = expm(-1j * gammas[i] * HC) @ GW2_psi\n",
    "    GW2_psi = expm(-1j * betas[i] * GW2_HB) @ GW2_psi\n",
    "abs(GW2_psi.conjugate().T @ GW2_QAOA) #### Fidelity between this matrix computation and the custom backend (notice how slow the matrix compute is)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f93c38",
   "metadata": {},
   "source": [
    "For the three dimensional warmstart we have \n",
    "$$|\\psi_\\textrm{int}\\rangle   = \\bigotimes_{j=0}^{n-1} \\left[\\cos\\left(\\frac{\\theta_j}{2}\\right)|0\\rangle + e^{i\\phi_j}\\sin\\left(\\frac{\\theta_j}{2}\\right)|1\\rangle\\right]$$\n",
    "$$H_B = \\bigoplus_{j=0}^{n-1} (\\cos(\\theta_j)\\sin(\\phi) X  +   \\sin(\\theta_j)\\sin(\\phi)  Y  + \\cos(\\phi) Z)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ed8168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.881784197001252e-15+0j)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GW3_rotated_angles = vertex_on_top(GW3_angles,0)\n",
    "\n",
    "GW3_HB = Q3_Hamiltonian(GW3_rotated_angles)\n",
    "GW3_psi_init = GW3_circ_data[0]\n",
    "\n",
    "np.linalg.eigvalsh(GW3_HB)[-1] - GW3_psi_init.conjugate().T @ GW3_HB @ GW3_psi_init  ###The initial state is always the maximal eigenvalue of the HB operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "874a7c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000056"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GW3_psi = GW3_psi_init\n",
    "for i in range(p):\n",
    "    GW3_psi = expm(-1j * gammas[i] * HC) @ GW3_psi\n",
    "    GW3_psi = expm(-1j * betas[i] * GW3_HB) @ GW3_psi\n",
    "\n",
    "abs(GW3_psi.conjugate().T @ GW3_QAOA) #### Fidelity between this matrix computation and the custom backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6186a6b4",
   "metadata": {},
   "source": [
    "For no warmstart we have\n",
    "$$|\\psi_\\textrm{int}\\rangle   = H^{\\otimes}|0\\rangle $$\n",
    "$$H_B = \\bigoplus_{j=0}^{n-1} X$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82af33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2434497875801753e-14+0j)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "HB = default_Hamiltonian(n)\n",
    "psi_init = np.ones(2**n)/np.sqrt(2**n)\n",
    "\n",
    "np.linalg.eigvalsh(HB)[-1] - psi_init.conjugate().T @ HB @ psi_init  ###The initial state is always the maximal eigenvalue of the HB operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "280dd78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999949"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi = psi_init\n",
    "for i in range(p):\n",
    "    psi = expm(-1j * gammas[i] * HC) @ psi\n",
    "    psi = expm(-1j * betas[i] * HB) @ psi\n",
    "\n",
    "abs(psi.conjugate().T @ default_QAOA) #### Fidelity between this matrix computation and the custom backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d74a44",
   "metadata": {},
   "source": [
    "### Gradient Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d39e4b",
   "metadata": {},
   "source": [
    "The function we are aiming to optimize is \n",
    "$$C(\\theta) = C(\\beta,\\gamma) = \\langle \\psi | H | \\psi \\rangle$$\n",
    "Where \n",
    "$$|\\psi\\rangle = \\prod_{m=1}^p e^{-\\beta_m H_B } e^{-\\gamma_m H_C }|\\psi_\\textrm{init}\\rangle$$\n",
    "And $\\theta$ is a vector of the parameters, here $\\beta,\\gamma$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67094af3",
   "metadata": {},
   "source": [
    "In order to determine how ''trainable'' a circuit is, we can compute gradients of the cost.\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta_\\mu}C(\\theta)=\\left\\langle \\left.\\frac{\\partial\\psi}{\\partial \\theta_\\mu} \\right| H | \\psi \\right\\rangle\n",
    "+\\left\\langle \\psi | H \\left|  \\frac{\\partial\\psi}{\\partial \\theta_\\mu}\\right.\\right\\rangle$$\n",
    "$$=2\\Re\\left[\\left\\langle \\left.\\frac{\\partial\\psi}{\\partial \\theta_\\mu} \\right|  H  |\\psi \\right\\rangle \\right]$$\n",
    "\n",
    "The total gradient of this function is a vector containing all of the partial derivatives. It lives in $\\mathbb{R}^{2p}$, half of the components are from $\\beta$ and half are from $\\gamma$\n",
    "\n",
    "Before we were concerned wih determining the value of C given $(\\beta,\\gamma)$, now we are interested in how the gradients behave. The difference is the first is a question of *training* while these second is a question of *trainability*.\n",
    "\n",
    "We will also write this gradient as $\\partial_\\mu C$ for convenience. The function ```QAOA_gradient_eval``` will compute these gradients. It takes in the same parameters as the QAOA evaluation circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0046e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Numerically estimate gradient \n",
    "def gradient(f,x,eps=1e-7):\n",
    "    grads = []\n",
    "    for i in range(len(x)):\n",
    "        perturb = np.zeros(len(x))\n",
    "        perturb[i] = eps \n",
    "        grads.append((f(x+perturb)-f(x-perturb))/(2*eps))\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b24a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0311618046489182e-08\n"
     ]
    }
   ],
   "source": [
    "### We can test that the analytical gradient methods line up with the numerical gradients\n",
    "QAOA_cost = lambda params: expval(precomp,QAOA_eval(precomp,params))\n",
    "print(f\"{np.linalg.norm(gradient(QAOA_cost, circuit_params) - QAOA_gradient_eval(precomp,circuit_params))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84ddbfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1188491141838045e-08\n"
     ]
    }
   ],
   "source": [
    "### We can test that the analytical gradient methods line up with the numerical gradients\n",
    "QAOA_cost = lambda params: expval(precomp,QAOA_eval(precomp,params,mixer_ops=GW2_circ_data[1],init=GW2_circ_data[0]))\n",
    "print(f\"{np.linalg.norm(gradient(QAOA_cost, circuit_params) - QAOA_gradient_eval(precomp,circuit_params,mixer_ops=GW2_circ_data[1],init=GW2_circ_data[0]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6c78f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4519345317000275e-08\n"
     ]
    }
   ],
   "source": [
    "### We can test that the analytical gradient methods line up with the numerical gradients\n",
    "QAOA_cost = lambda params: expval(precomp,QAOA_eval(precomp,params,mixer_ops=GW3_circ_data[1],init=GW3_circ_data[0]))\n",
    "print(f\"{np.linalg.norm(gradient(QAOA_cost, circuit_params) - QAOA_gradient_eval(precomp,circuit_params,mixer_ops=GW3_circ_data[1],init=GW3_circ_data[0]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e20c14",
   "metadata": {},
   "source": [
    "To measure how trainable a circuit is, we first compute the variance of the gradient (so the variance in each component) and then do an expectation value over all components \n",
    "$$\\mathbb{V} = \\mathbb{E}_\\mu\\left[\\textrm{Var} \\partial_\\mu C(\\beta,\\gamma)\\right]$$\n",
    "\n",
    "This is accomplished by the  ```QAOA_variance_sample``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ca036aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=50\n",
    "default_var = QAOA_variance_sample(precomp,p,shots=1)\n",
    "GW2_var = QAOA_variance_sample(precomp,p,mixer_ops=GW2_circ_data[1],init=GW2_circ_data[0],shots=1)\n",
    "GW3_var = QAOA_variance_sample(precomp,p,mixer_ops=GW3_circ_data[1],init=GW3_circ_data[0],shots=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4a9b542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Variance: 0.0\n",
      "GW2 Variance: 0.0\n",
      "GW3 Variance: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Default Variance: {default_var}\")\n",
    "print(f\"GW2 Variance: {GW2_var}\")\n",
    "print(f\"GW3 Variance: {GW3_var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4adb55",
   "metadata": {},
   "source": [
    "### To do List\n",
    "Near Term:\n",
    "* Try to get a method that parallelize the variance estimation. The variance is essentially just a for loop that computes a bunch of gradients with random parameters, so it should be easy to parallel process.\n",
    "* Get plots that show variance versus depth and versus number of qubits for a few graphs\n",
    "* Explore different graph distributions for those plots (GNP, NWS, etc.)\n",
    "\n",
    "Slightly Further Term:\n",
    "* Figure out a computationally efficient way to do Lie Algebra "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
